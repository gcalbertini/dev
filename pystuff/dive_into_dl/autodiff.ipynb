{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid allocating new memory every time we take a derivative because deep learning requires successively computing derivatives with respect to the same parameters a great many times, and we might risk running out of memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also create x = torch.arange(4.0, requires_grad=True)\n",
    "x.requires_grad_(True)\n",
    "x.grad  # The gradient is None by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentiating the function y = 2x@x with respect to the column vector x. To start, we assign x an initial value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward() # take the gradient of y with respect to x;  derivative of 2x@x is 4x\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that PyTorch does not automatically reset the gradient buffer when we record a new gradient; the new gradient is added to the already-stored gradient. This behavior comes in handy when we want to optimize the sum of multiple objective functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0.]), tensor(28., grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()  # Reset the gradient\n",
    "x.grad, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a tensor $Y$, which has been computed directly or indirectly from tensor $X$.\n",
    "\n",
    "`Y.backward()` would calculate the derivative of each element of $Y$ w.r.t. each element of $X$. This gives us `N_out` (the number of elements in Y) masks with shape `X.shape`.\n",
    "\n",
    "However, `torch.backward()` enforces by default that the gradient that will be stored in `X.grad` shall be of the same shape as X. If `N_out=1`, there is no problem as we have only one mask. That is why you want to reduce Y to a single value...\n",
    "\n",
    "`some_loss_function.sum().backward()` calculates the sum of all the loss values across the batch and then performs backpropagation based on that sum. This means that each element of the batch contributes equally to the loss, regardless of its value. This can be useful in some scenarios, such as when you want to prioritize rare events that have a small number of occurrences in the batch. If you sum your loss you will end up scaling your loss value and the gradients that are inferred from it uncontrollably -> overflow after some time.\n",
    "\n",
    "`some_loss_function.mean().backward()` calculates the mean of all the loss values across the batch and then performs backpropagation based on that mean. This means that each element of the batch contributes equally to the loss, but the contribution is weighted by its value. This can be useful in scenarios where you want to prioritize elements of the batch that have a higher loss value, or when you want to ensure that the gradients are scaled appropriately.\n",
    "\n",
    "If `N_out>1`, Pytorch wants to take a weighted sum over the `N_out` gradient masks. But you need to supply the weights for this weighted sum! You can do this with the gradient argument:\n",
    "`Y.backward(gradient=weights_shaped_like_Y)`\n",
    "\n",
    "If you give every element of Y weight 1, you will get the same behaviour as using `torch.sum(Y).backward()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://zhang-yang.medium.com/the-gradient-argument-in-pytorchs-backward-function-explained-by-examples-68f266950c29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: We did not pass the ``gradient`` argument to ``backward()``, and this defaults to passing the value 1. PyTorch is calculating the Jacobian product. In the case of scalar values, ``.backward()`` w/o parameters is equivalent to ``.backward(torch.tensor(1.0))``. When input is a vector and output y = x1 + x2 is a scalar, the default gradient argument will also be 1s. If output is a vector then have something like y1 = f(x1) and y2 = f(x2), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can only compute partial derivatives for a *scalar* function. \n",
    "# What backwards() gives you is d(loss)/d(parameter) and you expect \n",
    "# a *single* gradient value per parameter.\n",
    "y = x.sum()\n",
    "y.backward(), x.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
